# File Processing Pipeline

## Problem Understanding
Create a pipeline that reads from a file, filters lines, and processes them.

## Approach & Methodology
- Count the number of words in each line.
- Explain how pipelines can be structured for efficient data processing.
- Provide examples of using processing pipelines in practice.

## LLMs Used
GPT-4 was used to assist in creating a file processing pipeline.

## Prompts & Responses
**1. How can I create a processing pipeline in Python?**  
Chain together functions that read, filter, and process data in a structured manner.

**2. What are the benefits of using a processing pipeline?**  
Pipelines allow for modular design, making it easier to manage and test each step of the data processing.

**3. Can I handle errors in my processing pipeline?**  
Yes, you can implement error handling at each stage of the pipeline to manage potential issues.
